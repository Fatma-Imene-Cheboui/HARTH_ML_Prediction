{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSn8VuU8aaIv"
      },
      "source": [
        "# **Support Vector Machine**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sd75CYTlaZnK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn import svm, datasets\n",
        "import sklearn.model_selection as model_selection\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSOHVW6cazHr"
      },
      "source": [
        "### **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMpAnzaZ8FaR",
        "outputId": "edb5d580-254e-4f88-acb3-4ae8d79c8dc1"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'combined_data_with_id_ordered.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Read the combined dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m combined_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcombined_data_with_id_ordered.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Check for missing values\u001b[39;00m\n\u001b[0;32m      5\u001b[0m missing_values \u001b[38;5;241m=\u001b[39m combined_df\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum()\n",
            "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'combined_data_with_id_ordered.csv'"
          ]
        }
      ],
      "source": [
        "# Read the combined dataset\n",
        "combined_df = pd.read_csv(\"combined_data_with_id_ordered.csv\")\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = combined_df.isnull().sum()\n",
        "print(\"Missing Values:\\n\", missing_values)\n",
        "\n",
        "\n",
        "# Convert 'timestamp' column to datetime format\n",
        "combined_df['timestamp'] = pd.to_datetime(combined_df['timestamp'])\n",
        "\n",
        "# Perform feature scaling\n",
        "columns_to_scale = ['back_x', 'back_y', 'back_z', 'thigh_x', 'thigh_y', 'thigh_z']\n",
        "scaler = StandardScaler()\n",
        "combined_df[columns_to_scale] = scaler.fit_transform(combined_df[columns_to_scale])\n",
        "\n",
        "\n",
        "# Display the first few rows of the modified DataFrame\n",
        "print(\"\\nModified DataFrame:\")\n",
        "print(combined_df.head())\n",
        "\n",
        "# Function to detect and remove extreme outliers using the IQR method with a higher multiplier\n",
        "def remove_extreme_outliers_iqr(df, columns, multiplier=3.0):\n",
        "    for column in columns:\n",
        "        Q1 = df[column].quantile(0.25)\n",
        "        Q3 = df[column].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - multiplier * IQR\n",
        "        upper_bound = Q3 + multiplier * IQR\n",
        "        df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
        "    return df\n",
        "\n",
        "# Apply the outlier removal function to the relevant columns with a higher multiplier\n",
        "columns_to_check = columns_to_scale  # The same columns that were scaled\n",
        "original_shape = combined_df.shape\n",
        "cleaned_df = remove_extreme_outliers_iqr(combined_df, columns_to_check, multiplier=3.0)\n",
        "cleaned_shape = cleaned_df.shape\n",
        "\n",
        "# Display the first few rows of the cleaned DataFrame\n",
        "print(\"\\nCleaned DataFrame:\")\n",
        "print(cleaned_df.head())\n",
        "\n",
        "# Display the number of rows before and after removing outliers\n",
        "print(\"\\nOriginal number of rows:\", original_shape[0])\n",
        "print(\"Number of rows after removing outliers:\", cleaned_shape[0])\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAlZ6XY5hYSn"
      },
      "source": [
        "## **SVM with a sample**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4Todq8ohhgS9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Number of rows in the sampled DataFrame: 300000\n",
            "\n",
            "Number of instances in each class after sampling:\n",
            "label\n",
            "7      126294\n",
            "1       73017\n",
            "6       35175\n",
            "13      27872\n",
            "3       11995\n",
            "2       11090\n",
            "4        3967\n",
            "14       3488\n",
            "5        3270\n",
            "130      2828\n",
            "140       601\n",
            "8         403\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "num_participants = 22\n",
        "sample_size =30000\n",
        "\n",
        "# Calculate the sample size per participant\n",
        "sample_size_per_participant = sample_size // num_participants\n",
        "\n",
        "# Perform stratified sampling\n",
        "sampled_df = cleaned_df.groupby('id', group_keys=False).apply(lambda x: x.sample(min(len(x), sample_size_per_participant)))\n",
        "\n",
        "# If the total sampled rows are less than the desired sample size, sample the remaining randomly\n",
        "if len(sampled_df) < sample_size:\n",
        "    remaining_sample_size = sample_size - len(sampled_df)\n",
        "    remaining_sample = cleaned_df.drop(sampled_df.index).sample(remaining_sample_size)\n",
        "    sampled_df = pd.concat([sampled_df, remaining_sample])\n",
        "\n",
        "# Display the number of rows in the sampled DataFrame\n",
        "print(\"\\nNumber of rows in the sampled DataFrame:\", len(sampled_df))\n",
        "\n",
        "# Display the number of each class in the sampled DataFrame\n",
        "if 'label' in sampled_df.columns:\n",
        "    class_counts = sampled_df['label'].value_counts()\n",
        "    print(\"\\nNumber of instances in each class after sampling:\")\n",
        "    print(class_counts)\n",
        "else:\n",
        "    print(\"\\n'Class' column not found in the DataFrame.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "otJI8v0EicBo"
      },
      "outputs": [],
      "source": [
        "# Select features and target\n",
        "features = ['back_x', 'back_y', 'back_z', 'thigh_x', 'thigh_y', 'thigh_z']\n",
        "X = sampled_df[features]\n",
        "y = sampled_df['label']\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGtohMBpgBLd"
      },
      "source": [
        "### **ovr (One-vs-Rest)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "rbf = svm.SVC(kernel='rbf', gamma=2, C=2, decision_function_shape = \"ovr\").fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iWIVXix7AO6r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy (RBF Kernel) on ovr:  86.42\n",
            "F1 on ovr: 0.8526058733503068\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.80      0.85      0.83     21986\n",
            "           2       0.83      0.76      0.79      3273\n",
            "           3       0.41      0.17      0.24      3637\n",
            "           4       0.42      0.21      0.28      1213\n",
            "           5       0.29      0.11      0.16      1006\n",
            "           6       0.74      0.91      0.82     10396\n",
            "           7       0.99      0.99      0.99     37907\n",
            "           8       0.93      0.89      0.91       111\n",
            "          13       0.83      0.86      0.84      8368\n",
            "          14       0.65      0.50      0.57      1081\n",
            "         130       0.57      0.53      0.55       839\n",
            "         140       0.61      0.52      0.56       183\n",
            "\n",
            "    accuracy                           0.86     90000\n",
            "   macro avg       0.67      0.61      0.63     90000\n",
            "weighted avg       0.85      0.86      0.85     90000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rbf_pred = rbf.predict(X_test)\n",
        "rbf_accuracy = accuracy_score(y_test, rbf_pred)\n",
        "\n",
        "print('Accuracy (RBF Kernel) on ovr: ', \"%.2f\" % (rbf_accuracy*100))\n",
        "print(\"F1 on ovr:\", f1_score(y_test, rbf_pred, average='weighted'))\n",
        "print(classification_report(y_test, rbf_pred))\n",
        "\n",
        "# 0.5 / 0.1 Accuracy (RBF Kernel):  85.79\n",
        "# 1 / 1 Accuracy (RBF Kernel):  87.23\n",
        "# 0.5 / 1 Accuracy (RBF Kernel):  86.28\n",
        "# 1.5 / 1.5 Accuracy (RBF Kernel):  87.65\n",
        "# 2 / 2 Accuracy (RBF Kernel):  87.74\n",
        "# 2.5 / 2.5 Accuracy (RBF Kernel):  87.69\n",
        "# 2.5 / 2 Accuracy (RBF Kernel):  87.64\n",
        "# 1.5 / 2 Accuracy (RBF Kernel):  87.68\n",
        "# 2 / 1.5 Accuracy (RBF Kernel):  87.69\n",
        "# 2.1 /2.1 87.74\n",
        "# 2.2 / 2.2 87.67"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITADkcwDDYh0"
      },
      "source": [
        "### **ovo (One-vs-One)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lQItDgIfDhv7"
      },
      "outputs": [],
      "source": [
        "rbf = svm.SVC(kernel='rbf', gamma=2, C=20, decision_function_shape = \"ovo\").fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q086V3y9DoxM",
        "outputId": "2994ecdc-6fa6-4e40-8bc3-472d3dc2f2a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy (RBF Kernel) on ovo:  86.42\n",
            "F1 on ovo : 0.8526058733503068\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.80      0.85      0.83     21986\n",
            "           2       0.83      0.76      0.79      3273\n",
            "           3       0.41      0.17      0.24      3637\n",
            "           4       0.42      0.21      0.28      1213\n",
            "           5       0.29      0.11      0.16      1006\n",
            "           6       0.74      0.91      0.82     10396\n",
            "           7       0.99      0.99      0.99     37907\n",
            "           8       0.93      0.89      0.91       111\n",
            "          13       0.83      0.86      0.84      8368\n",
            "          14       0.65      0.50      0.57      1081\n",
            "         130       0.57      0.53      0.55       839\n",
            "         140       0.61      0.52      0.56       183\n",
            "\n",
            "    accuracy                           0.86     90000\n",
            "   macro avg       0.67      0.61      0.63     90000\n",
            "weighted avg       0.85      0.86      0.85     90000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rbf_pred = rbf.predict(X_test)\n",
        "rbf_accuracy = accuracy_score(y_test, rbf_pred)\n",
        "\n",
        "print('Accuracy (RBF Kernel) on ovo: ', \"%.2f\" % (rbf_accuracy*100))\n",
        "print(\"F1 on ovo :\", f1_score(y_test, rbf_pred, average='weighted'))\n",
        "print(classification_report(y_test, rbf_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8qzaZWrGTeN"
      },
      "source": [
        "ALMOST SAME RESULT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnJJMFbODAR_"
      },
      "source": [
        "----------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVHfXNmxAkeZ"
      },
      "source": [
        "## **SVM on an undersampled data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Select features and target\n",
        "features = ['back_x', 'back_y', 'back_z', 'thigh_x', 'thigh_y', 'thigh_z']\n",
        "X = cleaned_df[features]\n",
        "y = cleaned_df['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SHaNq3p8SZ4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label\n",
            "1      7808\n",
            "2      7808\n",
            "3      7808\n",
            "4      7808\n",
            "5      7808\n",
            "6      7808\n",
            "7      7808\n",
            "8      7808\n",
            "13     7808\n",
            "14     7808\n",
            "130    7808\n",
            "140    7808\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Apply RandomUnderSampler to balance the dataset\n",
        "under_sampler = RandomUnderSampler(random_state=42)\n",
        "X_usampled, y_usampled = under_sampler.fit_resample(X, y)\n",
        "\n",
        "class_counts = y_usampled.value_counts()\n",
        "print(class_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zg0G6rsnuWl"
      },
      "outputs": [],
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_usampled, y_usampled, test_size=0.3, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JH0wPPmU86Vh"
      },
      "outputs": [],
      "source": [
        "rbf = svm.SVC(kernel='rbf', gamma=5, C=20, decision_function_shape = \"ovr\").fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLa8Pd1C9UiK",
        "outputId": "f212e43e-fd6a-4896-9faf-4d8fa1004b02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy with undersampling (RBF Kernel):  68.10\n",
            "F1 Undersampling: 0.6785805810812949\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.45      0.41      0.43      2297\n",
            "           2       0.56      0.80      0.66      2325\n",
            "           3       0.50      0.48      0.49      2319\n",
            "           4       0.54      0.51      0.53      2303\n",
            "           5       0.52      0.45      0.48      2456\n",
            "           6       0.72      0.79      0.75      2388\n",
            "           7       0.97      0.98      0.98      2349\n",
            "           8       0.98      0.96      0.97      2347\n",
            "          13       0.65      0.61      0.63      2364\n",
            "          14       0.73      0.65      0.69      2391\n",
            "         130       0.76      0.72      0.74      2300\n",
            "         140       0.79      0.80      0.79      2270\n",
            "\n",
            "    accuracy                           0.68     28109\n",
            "   macro avg       0.68      0.68      0.68     28109\n",
            "weighted avg       0.68      0.68      0.68     28109\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rbf_pred = rbf.predict(X_test)\n",
        "rbf_accuracy = accuracy_score(y_test, rbf_pred)\n",
        "\n",
        "print('Accuracy with undersampling (RBF Kernel): ', \"%.2f\" % (rbf_accuracy*100))\n",
        "print(\"F1 Undersampling:\", f1_score(y_test, rbf_pred, average='weighted'))\n",
        "print(classification_report(y_test, rbf_pred))\n",
        "\n",
        "# 2 /20 Accuracy with undersampling and sampling (RBF Kernel):  69.87 F1 : 0.6964611004613767 WITH good f1 class"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
